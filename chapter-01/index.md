# Chapter 1 - Lexing

- lexing is the conversion of source code into tokens
- a lexer is also known as a tokeniser, or scanner
- tokens generated by the lexer are sent to the parser which builds an AST
- whitespace may or may not be significant in different lexers - e.g. in
    Python whitespace _is_ significant, and is thus converted into tokens.
    In languages where whitespace is not significant, the lexer may ignore
    generating tokens for whitespace





